# HOW_TO.md
## AI Chat v0.2.0 - Oktat√≥i √ötmutat√≥

---

## üìù **EREDETI FELADAT**

### 1. Felhaszn√°l√≥ k√©pes legyen f√°jlt felt√∂lteni
### 2. Rendszer chunkolja + embeddingelje + t√°rolja vector adatb√°zisban
### 3. Felhaszn√°l√≥ k√©pes legyen a f√°jl tartalm√°ra r√°k√©rdezni
### 4. Rendszer k√©pes legyen a megfelel≈ë chunkokat kiv√°lasztva relev√°ns v√°laszt gener√°lni

---

## ‚úÖ **MEGVAL√ìS√çT√ÅS & ELLEN≈êRZ√âS**

### üöÄ **Ind√≠t√°s**
```powershell
cd ai_chat_edu_v02
docker-compose up -d
```
**Frontend:** http://localhost:3000 | **Backend:** http://localhost:8000

---

### ‚úÖ **1. F√°jl Felt√∂lt√©s**

**Megval√≥s√≠t√°s:** 
- Frontend: **üìé** ikon (Chat input mez≈ët≈ël balra) ‚Üí DocumentUpload modal
- Backend: `POST /api/workflows/process-document` (single endpoint)
- T√°mogatott form√°tumok: PDF, TXT, Markdown (max 10MB)

**Tesztel√©s:**
1. Kattints **üìé** ikonra
2. V√°lassz f√°jlt: `test_files/test_doc.txt` vagy `chunk_test_fantasy_elfek_orkok.txt`
3. Upload gomb
4. **Elv√°rt:** "Document processed successfully" + document ID

---

### ‚úÖ **2. Automatikus Chunking + Embedding + T√°rol√°s**

**Megval√≥s√≠t√°s:**
- **Chunking:** RecursiveCharacterTextSplitter (500 token/chunk, 50 overlap)
- **Embedding:** OpenAI text-embedding-3-large (3072 dim)
- **PostgreSQL:** `documents` + `document_chunks` t√°bl√°k
- **Qdrant:** `document_chunks` collection (vector storage)

**Tesztel√©s (h√°tt√©r folyamat ellen≈ërz√©s):**
```powershell
# Chunk-ok ellen≈ërz√©se PostgreSQL-ben
docker exec ai_chat_edu_v02-backend-1 python /app/debug/check_docs_chunks.py
# Output: "test_doc.txt - 3 chunks"

# Vector embedding ellen≈ërz√©se Qdrant-ban
docker exec ai_chat_edu_v02-backend-1 python /app/debug/check_qdrant_data.py
# Output: "Tenant 1: 3 vectors"
```

**Elv√°rt:** Chunk count PostgreSQL == Qdrant vector count

---

### ‚úÖ **3. R√°k√©rdez√©s F√°jl Tartalm√°ra**

**Megval√≥s√≠t√°s:**
- Unified Chat Workflow (LangGraph)
- Intelligens routing: LLM d√∂nti el, hogy RAG keres√©s sz√ºks√©ges-e
- Chat interface: session-based conversation

**Tesztel√©s:**
1. V√°lassz tenantot: "ACME Corporation"
2. V√°lassz usert: "Alice Johnson"
3. √çrj k√©rd√©st: **"Mir≈ël sz√≥l a felt√∂lt√∂tt dokumentum?"**
4. **Elv√°rt:** LLM v√°lasz + forr√°s hivatkoz√°s (üìÑ test_doc.txt)

---

### ‚úÖ **4. Relev√°ns Chunk√∂k Kiv√°laszt√°sa + V√°laszgener√°l√°s**

**Megval√≥s√≠t√°s:**
- Query embedding ‚Üí Qdrant similarity search (TOP_K=5, min_score=0.1)
- Chunk filtering tenant_id alapj√°n (security)
- Retrieved chunks ‚Üí LLM context (GPT-3.5-turbo)
- Answer generation + source attribution

**Tesztel√©s (RAG pipeline r√©szletek):**
```powershell
# Backend logs: RAG workflow l√©p√©sek
docker logs ai_chat_edu_v02-backend-1 --tail 50 | Select-String "RAG|chunk|Qdrant"
```

**Elv√°rt kimenet a chatben:**
- V√°lasz tartalmazza a dokumentum specifikus inform√°ci√≥kat
- **Forr√°s hivatkoz√°s:** üìÑ "test_doc.txt" vagy "chunk_test_fantasy_elfek_orkok.txt"
- **Response time:** ~2-3s (l√°that√≥ bubor√©kban)

**Kontrollteszt (nem RAG query):**
- K√©rd√©s: **"Szia!"**
- **Elv√°rt:** Direkt LLM v√°lasz, NINCS forr√°s hivatkoz√°s (routing = CHAT)

---

## üéØ **A RENDSZER EZEN FEL√úL M√âG...**

### Multi-tenant Architecture
- T√∂bb c√©g (tenant) p√°rhuzamos m≈±k√∂d√©se
- Adatok teljes szepar√°ci√≥ja (PostgreSQL + Qdrant filters)
- Tenant-specifikus system prompt (c√©g-szint≈± AI testreszab√°s)

### Multi-user Support
- User-szint≈± system prompt (szem√©lyre szabott AI viselked√©s)
- User-specifikus dokumentumt√°r (private vs tenant visibility)
- Session management (t√∂bb besz√©lget√©s p√°rhuzamosan)

### Intelligent Routing (LangGraph Agent Loop)
- Automatikus d√∂nt√©s: CHAT | RAG | LIST | EXPLICIT_MEMORY
- Nincs hardcoded keyword detection
- Adapt√≠v workflow (max 10 iter√°ci√≥)

### Chat History & Context Awareness
- PostgreSQL persistence (metadata oszlop: sources, rag_params)
- Oldal friss√≠t√©s ut√°n chat megmarad
- Kontextu√°lis follow-up k√©rd√©sek ("√âs hol √©lnek?" ‚Üí √©rti az "≈ëk" = elfek)

### Explicit Memory (Fact Extraction)
- LLM-alap√∫ fact extraction ("Kedvenc k√∂nyv: XYZ")
- Automatikus spell-check (GPT-4o mini)
- Long-term memory t√°rol√°s (k√ºl√∂n Qdrant collection)

### 3-tier Cache Architecture
- In-memory cache (tenant/user data)
- PostgreSQL query cache
- DEV_MODE runtime toggle (system.ini)
- Performance: 47ms ‚Üí 13ms (cache HIT)

### Debug & Development Tools
- Debug panel: PostgreSQL + Qdrant reset
- Cache statistics endpoint
- UTF-8 encoding support
- PowerShell test scripts (`debug/` k√∂nyvt√°r)

---

**Verzi√≥:** 0.2.0 | **Dokument√°ci√≥:** `docs/` k√∂nyvt√°r (CACHE_ARCHITECTURE.md, LANGGRAPH_WORKFLOWS.md)  
**Utols√≥ friss√≠t√©s:** 2026-01-02
