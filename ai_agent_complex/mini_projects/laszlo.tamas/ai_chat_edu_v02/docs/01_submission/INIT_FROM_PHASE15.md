# INIT_PROMPT_2.md
## Phase 2.0 ‚Äì RAG + Knowledge Management (FULL SCOPE)

---

## üìú AGENT CONSTITUTION BET√ñLT√âSE (K√ñTELEZ≈ê)

‚ö†Ô∏è **Ez a prompt az AGENT_CONSTITUTION.md szab√°lyai alapj√°n m≈±k√∂dik.**

**Kritikus referenci√°k:**
- **Section 3.2:** PLAN ‚Üí PERMISSION ‚Üí CODE (implement√°ci√≥ csak enged√©llyel)
- **Section 3.3:** Fejleszt√©si workflow (BUILD ‚Üí TEST ‚Üí REPORT ciklus)
- **Section 4:** Failure Mode (bizonytalans√°g eset√©n K√âRDEZ √©s MEG√ÅLL)
- **Section 5:** Red Lines (tilos hardcode-ol√°s, input-specifikus workaround)
- **Section 6.1:** TODO policy (k√ºl√∂n f√°jl, nem az INIT_PROMPT-ban)
- **Section 6.4:** Debug f√°jlok kezel√©se (debug/ k√∂nyvt√°r haszn√°lata)

üëâ **Ha az INIT_PROMPT √©s az AGENT_CONSTITUTION k√∂z√∂tt ellentmond√°s van:**  
**‚Üí az AGENT_CONSTITUTION az els≈ëdleges.**

---

## 0Ô∏è‚É£ KONFIGUR√ÅCI√ìS ALAPF√ÅJLOK (K√ñTELEZ≈ê ELS≈ê L√âP√âS)

A fejleszt√©s megkezd√©se el≈ëtt **K√ñTELEZ≈êEN** l√©tre kell hozni az al√°bbi konfigur√°ci√≥s f√°jlokat.

‚ö†Ô∏è **SZAB√ÅLYOK:**
- √âRT√âKET SEHOL NEM SZABAD MEGADNI
- CSAK v√°ltoz√≥nevek szerepelhetnek
- Ezek **strukt√∫r√°t defini√°lnak**, nem konfigur√°ci√≥t
- Az √©rt√©keket a futtat√°si k√∂rnyezet adja meg

---

### 0.1 PROMPT HIERARCHIA (K√ñTELEZ≈ê MODELL)

```
system.ini              ‚Üí APPLICATION PROMPT
tenants.system_prompt   ‚Üí TENANT POLICY
users.system_prompt     ‚Üí USER PREFERENCES
runtime task prompt     ‚Üí QUESTION + RETRIEVED CONTEXT
```

Ez a sorrend **nem megford√≠that√≥**.

**MAGYAR√ÅZAT:**

A hierarchia azt hat√°rozza meg, hogyan √©p√ºl fel az LLM sz√°m√°ra a teljes k√∂rnyezeti prompt:

1. **System szint** (`system.ini` ‚Üí APPLICATION PROMPT)  
   - Rendszerszinten meghat√°rozott utas√≠t√°sok
   - **NEM √çRHAT√ì FEL√úL** semmilyen alacsonyabb szinten
   - Glob√°lis m≈±k√∂d√©si szab√°lyok

2. **Tenant szint** (`tenants.system_prompt` ‚Üí TENANT POLICY)  
   - Tenant-specifikus szab√°lyok
   - A tenant-ban l√©v≈ë **MINDEN userre vonatkozik**
   - V√°llalati policy-k√©nt m≈±k√∂dik
   - Nem √≠rhatja fel√ºl a system szintet

3. **User szint** (`users.system_prompt` ‚Üí USER PREFERENCES)  
   - User-specifikus preferenci√°k
   - Nem √≠rhatja fel√ºl a system vagy tenant szab√°lyokat
   - Szem√©lyre szab√°s

4. **Runtime szint** (task prompt)  
   - Aktu√°lis k√©rd√©s + RAG context
   - A legalacsonyabb priorit√°s
   - Nem √≠rhat fel√ºl semmilyen magasabb szintet

**P√âLDA:**
- System: "Mindig magyar nyelven v√°laszolj"
- Tenant: "Soha ne adj p√©nz√ºgyi tan√°csot"
- User: "Informat√≠v st√≠lusban v√°laszolj"
- Runtime: "Mi a r√©szv√©ny √°rfolyama?" ‚Üê Ez NEM kaphat p√©nz√ºgyi tan√°csot, m√©g ha k√©ri is

---

## üéØ PROJEKT C√âL (PHASE 2.0)

Egy **multi-tenant, user-aware bels≈ë AI rendszer**, amely:

- dokumentum-, term√©k- √©s chat-alap√∫ tud√°st kezel
- Retrieval-Augmented Generation (RAG) architekt√∫r√°t haszn√°l
- PostgreSQL + Qdrant + LangGraph stackre √©p√ºl
- oktat√°si / vizsga k√∂rnyezetben **v√©dhet≈ë**

Nem production rendszer.  
A c√©l: **tiszta, magyar√°zhat√≥ architekt√∫ra**.

---

## üõ†Ô∏è TECH STACK (K√ñTELEZ≈ê PARAM√âTEREK)

### Backend
- **Python**: 3.11+
- **Framework**: FastAPI 0.104.1
- **ASGI Server**: Uvicorn 0.24.0
- **Validation**: Pydantic 2.5.0
- **LLM Client**: OpenAI 1.54.0
- **Orchestration**: LangGraph 0.0.26
- **LangChain**: langchain-core 0.1.25+, langchain-openai 0.0.5

### Frontend
- **Framework**: React 18.2.0
- **Language**: TypeScript 5.3.3
- **Build Tool**: Vite 5.0.8
- **Styling**: Native CSS (no framework)

### Database & Vector Store
- **Relational DB**: PostgreSQL 15+ (via psycopg2-binary 2.9.9)
- **Vector DB**: Qdrant (latest stable)
- **Embedding Model**: OpenAI `text-embedding-3-large` (3072 dim)

### Infrastructure
- **Containerization**: Docker + Docker Compose
- **Ports**: 
  - Backend: 8000
  - Frontend: 3000
  - PostgreSQL: 5432 (Docker local)
  - Qdrant: 6333 (HTTP API), 6334 (gRPC)

### Environment
- `.env` file k√∂telez≈ë
- Environment v√°ltoz√≥k: OPENAI_API_KEY, POSTGRES_*, USE_LANGGRAPH

---

## üß† VECTOR DATABASE STRAT√âGIA (K√ñTELEZ≈ê)

**Egy Qdrant instance, k√ºl√∂n collection√∂k:**

- document_chunks
- longterm_chat_memory
- product_knowledge

Ezek **SOHA** nem keverhet≈ëk.

---

## üü• P0 ‚Äì CORE RAG ‚úÖ COMPLETED (P0.1-P0.8)

**ST√ÅTUSZ:** Core RAG pipeline **100% k√©sz** √©s m≈±k√∂dik LangGraph workflow-kban.

**AMIT M√ÅR TUDSZ:**
- ‚úÖ P0.1-P0.6: Dokumentum felt√∂lt√©s, chunkol√°s, embedding, Qdrant retrieval
- ‚úÖ P0.7: LangGraph RAG workflow (teljes pipeline)
- ‚úÖ P0.8: Intelligent RAG routing (conversational vs document k√©rd√©sek)

**K√ñVETKEZ≈ê:** P0.9 tov√°bbfejleszt√©sek (UX + performance)

---

### P0.1 File upload ‚úÖ COMPLETED (LangGraph)
- PDF / TXT / MD
- tenant + user kontextus
- DB-be √≠r√°s: documents t√°bla

**ENDPOINT:**
- ~~POST /api/documents/upload~~ ‚Üí **POST /api/workflows/process-document** (automated)
- Multipart form-data: file + tenant_id + user_id + visibility

**DB INSERT (documents t√°bla):**
- tenant_id: request-b≈ël
- user_id: request-b≈ël (auth alapj√°n)
- visibility: 'private' vagy 'tenant'
- source: 'upload' (fix √©rt√©k)
- title: file.filename
- content: file text tartalma (extracted)
- created_at: auto (DEFAULT now())

**DONE WHEN:**
- [x] POST /api/workflows/process-document endpoint m≈±k√∂dik ‚úÖ
- [x] File validation: max 10MB, csak PDF/TXT/MD ‚úÖ
- [x] File content extrakci√≥ (PDF ‚Üí text, TXT/MD ‚Üí direct read) ‚úÖ
- [x] documents t√°bl√°ba INSERT val√≥s mez≈ëkkel ‚úÖ
- [x] Response: {"document_id": <id>, "summary": {...}} ‚úÖ
- [x] HTTP 201 Created, 400 invalid file ‚úÖ
- [ ] Frontend: file picker + upload gomb (UI TODO)

### P0.2 Dokumentum adatmodell (PostgreSQL)
- documents
- document_chunks
- visibility: private / tenant
- source metaadatok

**VAL√ìS DB S√âMA (m√°r l√©tezik):**

**documents t√°bla:**
- id (bigint, PK)
- tenant_id (bigint, FK ‚Üí tenants.id)
- user_id (bigint, FK ‚Üí users.user_id, nullable)
- visibility (text: 'private' | 'tenant')
- source (text: forr√°s t√≠pusa)
- title (text: dokumentum c√≠me/f√°jln√©v)
- content (text: teljes dokumentum tartalma)
- created_at (timestamp)

**document_chunks t√°bla:**
- id (bigint, PK)
- tenant_id (bigint, FK ‚Üí tenants.id)
- document_id (bigint, FK ‚Üí documents.id)
- chunk_index (integer)
- start_offset (integer)
- end_offset (integer)
- content (text)
- source_title, source_section, source_page_from, source_page_to (metadata)
- qdrant_point_id (uuid: Qdrant kapcsolat)
- embedded_at (timestamp)
- created_at (timestamp)

**DONE WHEN:**
- [x] documents t√°bla l√©tezik ‚úÖ
- [x] document_chunks t√°bla l√©tezik ‚úÖ
- [x] Foreign keys: document_chunks.document_id ‚Üí documents.id ‚úÖ
- [x] Index: document_id, tenant_id ‚úÖ
- [ ] Migration script (ha √∫j mez≈ë kell): NEM SZ√úKS√âGES

### P0.3 Chunkol√°s ‚úÖ COMPLETED
- strat√©gia: **recursive** (system.ini)
- chunk_size: **500 tokens** (~2000 chars)
- overlap: **50 tokens** (~200 chars)
- offsetek √©s indexek t√°rol√°sa PostgreSQL-ben

**IMPLEMENT√ÅCI√ì:** `services/chunking_service.py` + LangGraph workflow node

**DONE WHEN:**
- [x] Chunking service implement√°lva ‚úÖ
- [x] RecursiveCharacterTextSplitter haszn√°lata (LangChain) ‚úÖ
- [x] Chunk index, start_offset, end_offset sz√°m√≠t√°sa helyes ‚úÖ
- [x] PostgreSQL-be √≠r√°s sikeres minden chunk-kal ‚úÖ
- [x] Workflow: chunk_document node m≈±k√∂dik ‚úÖ

### P0.4 Embedding pipeline (documents) ‚úÖ COMPLETED
- chunk ‚Üí embedding
- large modell (text-embedding-3-large)
- id≈ëb√©lyeg r√∂gz√≠t√©se

**IMPLEMENT√ÅCI√ì:** `services/embedding_service.py` + LangGraph workflow node

**DONE WHEN:**
- [x] OpenAI text-embedding-3-large haszn√°lata (3072 dim) ‚úÖ
- [x] Batch processing: max 100 chunk/call (system.ini: EMBEDDING_BATCH_SIZE) ‚úÖ
- [x] Embedding vektorok gener√°l√°sa minden chunk-hoz ‚úÖ
- [x] Error handling implement√°lva ‚úÖ
- [x] Timestamp: embedded_at mez≈ë PostgreSQL-ben ‚úÖ

### P0.5 Qdrant ‚Äì document_chunks collection ‚úÖ COMPLETED
- payload: tenant_id, document_id, chunk_id, visibility
- cosine similarity
- tenant sz≈±r√©s k√∂telez≈ë

**IMPLEMENT√ÅCI√ì:** `services/qdrant_service.py` + workflow upsert node

**DONE WHEN:**
- [x] Qdrant collection l√©tezik: prefix + "document_chunks" ‚úÖ
- [x] Vector size: 3072 (text-embedding-3-large) ‚úÖ
- [x] Distance metric: Cosine ‚úÖ
- [x] Payload schema: {tenant_id, document_id, chunk_id, visibility, content_preview} ‚úÖ
- [x] Filter on payload: tenant_id (gyors sz≈±r√©s) ‚úÖ
- [x] Workflow: upsert_to_qdrant node m≈±k√∂dik ‚úÖ

### P0.6 Retrieval pipeline ‚úÖ COMPLETED
- query ‚Üí embedding
- similarity search
- Top-K chunk
- forr√°smeg≈ërz√©s

**IMPLEMENT√ÅCI√ì:** `services/rag_workflow.py` - retrieve_chunks_node

**DONE WHEN:**
- [x] Query text ‚Üí OpenAI embedding ‚úÖ
- [x] Qdrant search with tenant_id filter (k√∂telez≈ë) ‚úÖ
- [x] Top-K = 5 (system.ini: TOP_K_DOCUMENTS) ‚úÖ
- [x] Min score threshold = 0.7 (system.ini: MIN_SCORE_THRESHOLD) ‚úÖ
- [x] Response: List[DocumentChunk] with document_id, content, score ‚úÖ
- [x] RAG workflow retrieve_document_chunks node m≈±k√∂dik ‚úÖ

### P0.7 LangGraph RAG workflow

**WORKFLOW DIAGRAM:**

```
START
 ‚Üí validate_input          [ellen≈ërz√©s: tenant_id, user_id, query]
 ‚Üí build_context           [prompt hierarchia √∂sszeszed√©se]
 ‚Üí retrieve_document_chunks [Qdrant similarity search]
 ‚Üí check_retrieval_results  [van-e relev√°ns chunk?]
    ‚îú‚îÄ YES ‚Üí generate_answer_from_context
    ‚îú‚îÄ NO  ‚Üí generate_fallback_response
 ‚Üí END
```

**ERROR HANDLING:**
- Minden node try-catch wrapper-rel
- Hiba eset√©n: error state + fallback v√°lasz
- Timeout: 30s per node (konfigurat√≠v)
- Retry logic: NEM implement√°lt Phase 2.0-ban

**STATE DEFIN√çCI√ì (Python TypedDict):**

```python
from typing import TypedDict, List, Optional

class DocumentChunk(TypedDict):
    chunk_id: int
    document_id: int
    content: str
    metadata: dict
    similarity_score: float

class UserContext(TypedDict):
    tenant_id: int
    user_id: int
    tenant_prompt: Optional[str]
    user_prompt: Optional[str]
    user_language: str  # 'hu' | 'en'

class RAGState(TypedDict):
    # Input
    query: str
    user_context: UserContext
    
    # Intermediate
    system_prompt: str
    combined_prompt: str
    retrieved_chunks: List[DocumentChunk]
    has_relevant_context: bool
    
    # Output
    final_answer: str
    sources: List[int]  # document_id list
    error: Optional[str]
```

**NODE FELEL≈êSS√âGEK:**

- `validate_input`: tenant_id, user_id, query nem √ºres
- `build_context`: system.ini + tenant + user prompt √∂sszef≈±z√©s
- `retrieve_document_chunks`: query ‚Üí embedding ‚Üí Qdrant search ‚Üí top-K
- `check_retrieval_results`: similarity_score >= 0.7 threshold
- `generate_answer_from_context`: LLM h√≠v√°s context + query-vel
- `generate_fallback_response`: "Nincs relev√°ns dokumentum" v√°lasz

**DONE WHEN:**
- [x] LangGraph StateGraph defini√°lva RAGState-tel
- [x] Minden node implement√°lva fenti felel≈ëss√©gekkel
- [x] Conditional edge: check_retrieval_results ‚Üí YES/NO
- [x] Error state kezel√©s minden node-ban
- [x] POST /api/chat/rag endpoint LangGraph-ot h√≠vja
- [x] Teszt: query + user_context ‚Üí final_answer + sources
- [x] Frontend: v√°lasz megjelen√≠t√©se source attribution-nel

---

### P0.8 Intelligent RAG Routing (‚úÖ COMPLETED - Enhancement)

**‚ö†Ô∏è NOTE:** Ez egy P0.7 tov√°bbfejleszt√©s, amely a UX jav√≠t√°sa √©rdek√©ben ker√ºlt implement√°l√°sra.

**PROBL√âMA:** P0.7 minden query-re RAG retrieval-t ind√≠tott, m√©g k√∂sz√∂n√©sekre is ("szia" ‚Üí "Nincs relev√°ns dokumentum").

**MEGOLD√ÅS:** LLM-based decision node a RAG sz√ºks√©gess√©g√©r≈ël.

**√öJ WORKFLOW:**

```
START
 ‚Üí validate_input
 ‚Üí build_context
 ‚Üí decide_if_rag_needed    [üÜï LLM d√∂nt√©s: kell-e dokumentum?]
    ‚îú‚îÄ YES ‚Üí retrieve_document_chunks ‚Üí check_retrieval_results ‚Üí [answer | fallback]
    ‚îî‚îÄ NO  ‚Üí generate_direct_answer [norm√°l chat, NINCS RAG]
 ‚Üí END
```

**√öJ STATE FIELD:**

```python
class RAGState(TypedDict):
    # ... (eredeti fieldek)
    needs_rag: bool  # üÜï LLM decision: ig√©nyel-e RAG-et a query?
```

**√öJ NODE-OK:**
- `decide_if_rag_needed`: LLM elemzi a query-t (conversational vs document-related)
- `generate_direct_answer`: K√∂zvetlen v√°lasz NINCS RAG (gyors, besz√©lget√©shez)

**P√âLD√ÅK:**
- "szia" ‚Üí NO RAG ‚Üí "Szia! Miben seg√≠thetek?" (sources: [])
- "mi van a dokumentumban?" ‚Üí YES RAG ‚Üí document search + answer (sources: [1,2,3])

**EL≈êNY√ñK:**
- Term√©szetes besz√©lget√©s lehets√©ges
- Gyorsabb v√°lasz conversational query-kn√©l (nincs embedding + Qdrant overhead)
- Jobb UX: nincs zavar√≥ "nincs dokumentum" √ºzenet k√∂sz√∂n√©sekre

**R√âSZLETEK:** L√°sd [docs/P0.8_INTELLIGENT_RAG_ROUTING.md](./P0.8_INTELLIGENT_RAG_ROUTING.md)

**DONE WHEN:**
- [x] RAGState b≈ëv√≠tve needs_rag field-del
- [x] decide_if_rag_needed node implement√°lva
- [x] generate_direct_answer node implement√°lva
- [x] Routing logic: conversational vs RAG
- [x] Backend build + deploy
- [x] Teszt: "szia" ‚Üí conversational v√°lasz (nem "nincs dokumentum")
- [x] Teszt: "mi van a dokumentumban?" ‚Üí RAG aktiv√°l√≥dik

---

### P0.9 Planned Improvements (‚è≥ TODO)

**STATUS:** Pending implementation  
**PRIORITY:** HIGH (before P1)  
**GOAL:** UX √©s teljes√≠tm√©ny tov√°bbfejleszt√©sek a megl√©v≈ë RAG rendszeren

**R√âSZLETES TASK LIST:** L√°sd [`TODO_PHASE2.md ¬ß P0.9`](./TODO_PHASE2.md#-p09--ux--performance-improvements)

**F≈ëbb ter√ºletek:**
1. **P0.9.1** - Document Title Metadata (forr√°s c√≠mek megjelen√≠t√©se)
2. **P0.9.2** - Enhanced Source Attribution (oldalsz√°m, fejezet)
3. **P0.9.3** - Search Performance Optimization (Qdrant tuning, cache)
4. **P0.9.4** - Document Summary Generation (auto-summary hossz√∫ dokumentumokhoz)
5. **P0.9.5** - Keyword Detection Improvements (P0.8 routing finomhangol√°sa)

---

## üüß P1 ‚Äì KNOWLEDGE & MEMORY

**STATUS:** Pending implementation  
**PRIORITY:** MEDIUM (after P0.9)  
**R√âSZLETES TASK LIST:** L√°sd [`TODO_PHASE2.md ¬ß P1`](./TODO_PHASE2.md#-p1--knowledge--memory)

### P1.1 Long-term Chat Memory
**C√©l:** Session summaries t√°rol√°sa √©s retrieval kor√°bbi besz√©lget√©sekb≈ël

**F≈ëbb l√©p√©sek:**
- Session lez√°r√°sakor LLM summary gener√°l√°s
- Embedding + Qdrant `longterm_chat_memory` collection
- √öj session ind√≠t√°sakor previous session retrieval
- LangGraph node: `retrieve_chat_history`

**DB S√©ma:**
- [x] `chat_sessions` t√°bla l√©tezik ‚úÖ
- [x] `long_term_memories` t√°bla l√©tezik ‚úÖ

---

### P1.2 Product Knowledge
**C√©l:** Struktur√°lt term√©kadat t√°rol√°sa √©s RAG retrieval

**F≈ëbb l√©p√©sek:**
- `products` t√°bla l√©trehoz√°sa (PostgreSQL)
- Sz√∂veges reprezent√°ci√≥ gener√°l√°s
- Embedding + Qdrant `product_knowledge` collection
- Term√©k-specifikus retrieval pipeline

---

### P1.3 Multi-source RAG
**C√©l:** P√°rhuzamos keres√©s dokumentum + term√©k adatforr√°sokban

**F≈ëbb l√©p√©sek:**
- Keyword-based routing (document vs product)
- Parallel search mindk√©t collection-ben
- Result merging (similarity score alapj√°n)
- LangGraph node: `route_and_retrieve`

---

## üü® P2 ‚Äì ADMIN & SYSTEM

**STATUS:** Pending implementation  
**PRIORITY:** LOW (after P1)  
**R√âSZLETES TASK LIST:** L√°sd [`TODO_PHASE2.md ¬ß P2`](./TODO_PHASE2.md#-p2--admin--system)

### P2.1 Admin Fel√ºlet (Profil √©s Tenant Szerkeszt√©s)

**User Profile Editing (minden user):**
- Szerkeszthet≈ë mez≈ëk: firstname, lastname, nickname, email, default_lang, system_prompt
- API: GET/PATCH `/api/users/{user_id}`
- Frontend form + validation

**Tenant Admin (csak admin role):**
- Szerkeszthet≈ë mez≈ëk: key, name, system_prompt, is_active
- API: GET/PATCH `/api/tenants/{tenant_id}` (authorization check)
- Frontend: "Tenant Admin" tab (csak adminoknak l√°that√≥)

---

### P2.2 system.ini Konfigur√°ci√≥
- Glob√°lis application prompt
- Backend-only file (frontend NEM m√≥dos√≠thatja)
- Manu√°lis szerkeszt√©s + restart sz√ºks√©ges
- Prompt hierarchia: system.ini > tenant > user > runtime

---

### P2.3 README.md Frontend Megjelen√≠t√©s
- RAG pipeline magyar√°zat
- Postgres vs Qdrant szerep
- Collection-strat√©gia dokument√°ci√≥
- API endpoint: GET `/api/docs/readme`
- Frontend: "README" tab (markdown renderel√©s)

---

## ÔøΩ DEPLOYMENT & SETUP

### El≈ëfelt√©telek
- Docker + Docker Compose telep√≠tve
- OpenAI API key
- PostgreSQL (Docker local)
- Qdrant (Docker local)

### .env f√°jl konfigur√°ci√≥

**K√ñTELEZ≈ê k√∂rnyezeti v√°ltoz√≥k:**

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL_CHAT=gpt-3.5-turbo
OPENAI_MODEL_EMBEDDING=text-embedding-3-large

# PostgreSQL (Docker local)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=ai_chat_edu
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# Qdrant (Docker local)
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_USE_HTTPS=true
QDRANT_COLLECTION_PREFIX=r_d_ai_chat

# Application
USE_LANGGRAPH=true
ENV=development
LOG_LEVEL=INFO
BACKEND_PORT=8000
FRONTEND_PORT=3000
```

### Ind√≠t√°s l√©p√©sei

**1. K√∂rnyezet setup:**
```powershell
# .env file m√°sol√°sa
Copy-Item .env.example .env
# Szerkeszd az √©rt√©keket!
```

**2. Docker build & start:**
```powershell
docker-compose up --build
```

**3. Health check:**
- Backend: http://localhost:8000/health
- Frontend: http://localhost:3000

**4. PostgreSQL migr√°ci√≥:**
```powershell
# Ha van migration script
docker-compose exec backend python -m alembic upgrade head
```

**5. Qdrant collection l√©trehoz√°s:**
- Automatikus az els≈ë embedding push-n√°l
- Vagy manu√°lis: backend init script

### Le√°ll√≠t√°s
```powershell
docker-compose down
```

### Reset (clean slate)
```powershell
docker-compose down -v  # t√∂rli a volume-okat is
```

---

## ÔøΩüö¶ FEJLESZT√âSI SZAB√ÅLY (MEGSZEGHETETLEN)

Ha egy funkci√≥:
- nem seg√≠ti a RAG / knowledge meg√©rt√©s√©t, vagy
- nem magyar√°zhat√≥ el 5 perc alatt,

akkor **NEM ker√ºl be Phase 2.0-ba**.

---

## üîí Z√ÅR√ì UTAS√çT√ÅS AZ AI AGENTNEK

Te **kontroll√°ltan √©p√≠tesz**.

L√©p√©s ‚Üí build ‚Üí teszt ‚Üí felhaszn√°l√≥i j√≥v√°hagy√°s ‚Üí tov√°bb.

M√°sk√©pp **nem dolgozol**.

